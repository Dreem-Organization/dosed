{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dosed Training and Evaluation\n",
    "\n",
    "You need the data for training as memmaps, to get them you either:\n",
    "  - Go through `download_and_data_format_explanation.ipynb`\n",
    "\n",
    "or \n",
    "\n",
    "  - Run `bash ./minimum_example/download_and_format_data.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from settings import MINIMUM_EXAMPLE_SETTINGS as settings\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Retrieve index of memmaps containing all the informations regarding training data\n",
    "data_index_filename = settings[\"memmap_directory\"] + \"index.json\"\n",
    "data_index = json.load(open(data_index_filename, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train, validation and test dataset creation\n",
    "\n",
    "## First we select which records we want to train, validate and test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "from dosed.preprocessings import RescaleNormal, Invert, GaussianNoise\n",
    "from dosed.utils import Compose\n",
    "from dosed.datasets import BalancedEventDataset as dataset\n",
    "from dosed.models import DOSED3 as model\n",
    "from dosed.trainers import trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 21\n"
     ]
    }
   ],
   "source": [
    "records = data_index[\"records\"]\n",
    "random.seed(2019)\n",
    "random.shuffle(records)\n",
    "print(\"Number of records:\", len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take 11 records for training, 5 for validation and 5 for test.\n",
    "records_train = records[:11]\n",
    "records_validation = records[11:16]\n",
    "records_test = records[16:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we use the dataset class that will be use to generate sample for training and evaluation\n",
    "\n",
    "- window: Spindles have a duration of ~1 seconds, so we design the samples accordingly by choosing 10 seconds windows\n",
    "- ratio_positive: sample within a training batch will have a probability of \"ratio_positive\" to contain at least one spindle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10  # window duration in seconds\n",
    "ratio_positive = 0.5  # When creating the batch, sample containing at least one spindle will be drawn with that probability\n",
    "downsampling = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parameters = {\n",
    "    \"data_index_filename\": data_index_filename,\n",
    "    \"window\": window,\n",
    "    \"ratio_positive\": ratio_positive,\n",
    "    \"downsampling\": downsampling,\n",
    "}\n",
    "\n",
    "dataset_validation = dataset(records=records_validation, **dataset_parameters)\n",
    "dataset_test = dataset(records=records_test, **dataset_parameters)\n",
    "\n",
    "# for training add data augmentation\n",
    "dataset_parameters_train = {\n",
    "    \"transformations\": Compose([\n",
    "        GaussianNoise(),\n",
    "        RescaleNormal(),\n",
    "        Invert(),\n",
    "    ])\n",
    "}\n",
    "dataset_parameters_train.update(dataset_parameters)\n",
    "dataset_train = dataset(records=records_train, **dataset_parameters_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a network\n",
    "\n",
    "The main parameters for the network are:\n",
    "  - default event sizes : to choose according to a priori size of the event to detect, here spindles are around 1 second\n",
    "  - k_max : number of CNN layers\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_event_sizes = [0.7, 1, 1.3]\n",
    "k_max = 5\n",
    "kernel_size = 5\n",
    "probability_dropout = 0.1\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input feature map size: 320\n",
      "Input receptive field: 0\n",
      "Input size in seconds: 10.0 s\n",
      "Input receptive field in seconds: 0.0 s \n",
      "\n",
      "After layer 1:\n",
      "\tFeature map size: 160\n",
      "\tReceptive field: 6\n",
      "\tReceptive field in seconds: 0.1875 s\n",
      "After layer 2:\n",
      "\tFeature map size: 80\n",
      "\tReceptive field: 16\n",
      "\tReceptive field in seconds: 0.5 s\n",
      "After layer 3:\n",
      "\tFeature map size: 40\n",
      "\tReceptive field: 36\n",
      "\tReceptive field in seconds: 1.125 s\n",
      "After layer 4:\n",
      "\tFeature map size: 20\n",
      "\tReceptive field: 76\n",
      "\tReceptive field in seconds: 2.375 s\n",
      "After layer 5:\n",
      "\tFeature map size: 10\n",
      "\tReceptive field: 156\n",
      "\tReceptive field in seconds: 4.875 s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = data_index[\"sampling_frequency\"]\n",
    "\n",
    "net_parameters = {\n",
    "    \"detection_parameters\": {\n",
    "        \"overlap_non_maximum_suppression\": 0.5,\n",
    "        \"classification_threshold\": 0.7\n",
    "    },\n",
    "    \"default_event_sizes\": [\n",
    "        default_event_size * fs\n",
    "        for default_event_size in default_event_sizes\n",
    "    ],\n",
    "    \"k_max\": k_max,\n",
    "    \"kernel_size\": kernel_size,\n",
    "    \"pdrop\": probability_dropout,\n",
    "    \"downsampling\": downsampling,\n",
    "    \"fs\": fs,\n",
    "    \"input_size\": (dataset_train.input_size, dataset_train.number_of_channels),\n",
    "    \"number_of_classes\": dataset_train.number_of_classes,\n",
    "}\n",
    "net = model(**net_parameters)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the network\n",
    "\n",
    "Parameters are\n",
    "  - learning_rate\n",
    "  - loss type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_parameters = {\n",
    "    \"lr\": 5e-3,\n",
    "    \"weight_decay\": 1e-8,\n",
    "}\n",
    "loss_specs = {\n",
    "    \"type\": \"focal\",\n",
    "    \"parameters\": {\n",
    "        \"number_of_classes\": dataset_train.number_of_classes,\n",
    "        \"device\": device,\n",
    "    }\n",
    "}\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  0\n",
      "\u001b[32;1mLogging data to /tmp/tmplkmq9c40/train_history.json\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [35:59<1:37:10, 388.69s/it, best_metric_score=0.275, last_update=4, threshold=0.699]"
     ]
    }
   ],
   "source": [
    "trainer = trainers[\"adam\"](\n",
    "    net,\n",
    "    optimizer_parameters=optimizer_parameters,\n",
    "    loss_specs=loss_specs,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "best_net_train, best_metrics_train, best_threshold_train = trainer.train(\n",
    "    dataset_train,\n",
    "    dataset_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_net_train.predict_dataset(\n",
    "    dataset_test,\n",
    "    best_threshold_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "record = dataset_test.records[1]\n",
    "\n",
    "index_spindle = 29\n",
    "window_duration = 5\n",
    "frequency = 32\n",
    "\n",
    "# retrive spindle at the right index\n",
    "spindle_start = float(predictions[record][0][index_spindle][0]) / frequency\n",
    "spindle_end = float(predictions[record][0][index_spindle][1]) / frequency\n",
    "\n",
    "# center data window on annotated spindle \n",
    "start_window = spindle_start + (spindle_end - spindle_start) / 2 - window_duration\n",
    "stop_window = spindle_start + (spindle_end - spindle_start) / 2 + window_duration\n",
    "\n",
    "# Retrieve EEG data at right index\n",
    "index_start = int(start_window * frequency)\n",
    "index_stop = int(stop_window * frequency)\n",
    "y = dataset_test.signals[record][\"data\"][0][index_start:index_stop]\n",
    "\n",
    "# Build corresponding time support\n",
    "t = start_window + np.cumsum(np.ones(index_stop - index_start) * 1 / frequency)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(t, y)\n",
    "plt.axvline(spindle_end)\n",
    "plt.axvline(spindle_start)\n",
    "plt.ylim([-1, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
